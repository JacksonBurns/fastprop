{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `fastprop` Computational ADME Demo\n",
    "This notebook demonstrates training `fastprop` on the Computational ADME dataset by Fang and co-authors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieiving the Data\n",
    "The dataset is available on GitHub at [https://raw.githubusercontent.com/molecularinformatics/Computational-ADME/main/ADME_public_set_3521.csv](https://raw.githubusercontent.com/molecularinformatics/Computational-ADME/main/ADME_public_set_3521.csv) - `fastprop` can load it directly using this web address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastprop.io import read_input_csv\n",
    "\n",
    "target_names = {\n",
    "    \"HLM\": \"LOG HLM_CLint (mL/min/kg)\",\n",
    "    \"MDR1-MDCK ER\": \"LOG MDR1-MDCK ER (B-A/A-B)\",\n",
    "    \"Solubility\": \"LOG SOLUBILITY PH 6.8 (ug/mL)\",\n",
    "    \"RLM\": \"LOG RLM_CLint (mL/min/kg)\",\n",
    "    \"hPPB\": \"LOG PLASMA PROTEIN BINDING (HUMAN) (% unbound)\",\n",
    "    \"rPPB\": \"LOG PLASMA PROTEIN BINDING (RAT) (% unbound)\",\n",
    "}\n",
    "\n",
    "targets, smiles = read_input_csv(\n",
    "    \"https://raw.githubusercontent.com/molecularinformatics/Computational-ADME/main/ADME_public_set_3521.csv\",\n",
    "    \"SMILES\",\n",
    "    target_names.values(),  # this function will read the columns in the order that we ask\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the Metrics\n",
    "The reference study uses the Pearson correlation coefficient - we will do the same here!\n",
    "We modify the dictionary that `fastprop` uses to lookup scoring metrics, copying from the `r2_score` function and adapating it to our needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from fastprop.metrics import SCORE_LOOKUP\n",
    "from torchmetrics.functional.regression import pearson_corrcoef\n",
    "\n",
    "\n",
    "def r_score(truth: torch.Tensor, prediction: torch.Tensor, ignored: None, multitask: bool = False):\n",
    "    return pearson_corrcoef(prediction, truth)\n",
    "\n",
    "\n",
    "SCORE_LOOKUP[\"regression\"] = (r_score,) + SCORE_LOOKUP[\"regression\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Molecular Descriptors\n",
    "Now, we need to calculate the molecular descriptors for each of these species.\n",
    "We will save these to `cached_computational_adme_descriptors.csv` so that subsequent runs are faster!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from rdkit.Chem import MolFromSmiles\n",
    "from fastprop.descriptors import get_descriptors\n",
    "from fastprop.defaults import ALL_2D\n",
    "from fastprop.io import load_saved_descriptors\n",
    "\n",
    "cache_file = \"cached_computational_adme_descriptors.csv\"\n",
    "if os.path.exists(cache_file):\n",
    "    descriptors = load_saved_descriptors(cache_file)\n",
    "else:\n",
    "    descriptors = get_descriptors(\n",
    "        cache_file,\n",
    "        ALL_2D,\n",
    "        list(map(MolFromSmiles, smiles)),\n",
    "    ).to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Functions\n",
    "Since we have a few sub-datasets contained in this one dataset, let's write a single reusable function for training `fastprop` on each of them.\n",
    "We will use the [`astartes`](https://github.com/JacksonBurns/astartes) splitting package that `fastprop` uses behind-the-scenes to partition the data into training, validation, and testing sets using KMeans clustering on the molecular fingerprints, which evaluates the model's capacity to extrapolate into new chemical space.\n",
    "\n",
    "As a point of comparison we will also do the same 5-fold cross validation performed in the reference study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading and Model Instantiation\n",
    "First we write a little convenience function to handle scaling, preparing dataloaders, and instantiating `fastprop`.\n",
    "We will actually make two models - one which is a simple linear model (i.e. just a weighted sum of the inputs) as a baseline and a typical FNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastprop.model import fastprop\n",
    "from fastprop.data import fastpropDataLoader, fastpropDataset, standard_scale\n",
    "\n",
    "\n",
    "def create_loaders_and_models(descriptors, targets, train_indexes, val_indexes, test_indexes):\n",
    "    # re-scale the features and the targets\n",
    "    descriptors[train_indexes], feature_means, feature_vars = standard_scale(descriptors[train_indexes])\n",
    "    descriptors[val_indexes] = standard_scale(descriptors[val_indexes], feature_means, feature_vars)\n",
    "    descriptors[test_indexes] = standard_scale(descriptors[test_indexes], feature_means, feature_vars)\n",
    "    targets[train_indexes], targets_means, targets_vars = standard_scale(targets[train_indexes])\n",
    "    targets[val_indexes] = standard_scale(targets[val_indexes], targets_means, targets_vars)\n",
    "    targets[test_indexes] = standard_scale(targets[test_indexes], targets_means, targets_vars)\n",
    "\n",
    "    # initialize dataloaders and model, then train\n",
    "    train_dataloader = fastpropDataLoader(fastpropDataset(descriptors[train_indexes], targets[train_indexes]), shuffle=True, batch_size=32)\n",
    "    val_dataloader = fastpropDataLoader(fastpropDataset(descriptors[val_indexes], targets[val_indexes]))\n",
    "    test_dataloader = fastpropDataLoader(fastpropDataset(descriptors[test_indexes], targets[test_indexes]), batch_size=1024)\n",
    "\n",
    "    # train a linear baseline _and_ a 'real' model\n",
    "    baseline_model = fastprop(\n",
    "        fnn_layers=0,\n",
    "        hidden_size=1_613,\n",
    "        feature_means=feature_means,\n",
    "        feature_vars=feature_vars,\n",
    "        target_means=targets_means,\n",
    "        target_vars=targets_vars,\n",
    "        learning_rate=0.0001,\n",
    "    )\n",
    "    real_model = fastprop(\n",
    "        clamp_input=True,\n",
    "        fnn_layers=2,\n",
    "        hidden_size=1_800,\n",
    "        feature_means=feature_means,\n",
    "        feature_vars=feature_vars,\n",
    "        target_means=targets_means,\n",
    "        target_vars=targets_vars,\n",
    "        learning_rate=0.0001,\n",
    "    )\n",
    "    return baseline_model, real_model, train_dataloader, val_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation\n",
    "The reference study uses cross-validation rather than replicates, which we can implement using the `KFold` class from `scikit-learn`.\n",
    "\n",
    "The main difference between this and replicates is that we aggregate the predictions for all the folds and then calculate metrics at the end - when using replicates, we calculate performance metrics for each replicate and average them instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from copy import deepcopy\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def cross_validate_fastprop(\n",
    "    smiles_arr: np.ndarray,\n",
    "    descriptors_arr: np.ndarray,\n",
    "    targets_arr: np.ndarray,\n",
    "    outdir: str,\n",
    "):\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    real_predictions, baseline_predictions, fold_truth = [], [], []\n",
    "    for train_indexes, test_indexes in kf.split(np.arange(len(smiles_arr))):\n",
    "        descriptors = torch.tensor(descriptors_arr, dtype=torch.float32)\n",
    "        targets = torch.tensor(targets_arr, dtype=torch.float32)\n",
    "        baseline_model, real_model, train_dataloader, _, test_dataloader = create_loaders_and_models(\n",
    "            descriptors, targets, train_indexes, np.array([]), test_indexes\n",
    "        )\n",
    "        tensorboard_logger = TensorBoardLogger(\n",
    "            outdir,\n",
    "            name=\"tensorboard_logs\",\n",
    "            default_hp_metric=False,\n",
    "        )\n",
    "        trainer = Trainer(\n",
    "            max_epochs=30,\n",
    "            enable_progress_bar=False,\n",
    "            enable_model_summary=False,\n",
    "            logger=tensorboard_logger,\n",
    "            log_every_n_steps=1,\n",
    "            enable_checkpointing=False,\n",
    "            check_val_every_n_epoch=1,\n",
    "        )\n",
    "        trainer.fit(real_model, train_dataloader)\n",
    "        # the predict method will auto-magically scale the descriptors and then undo the scaling of the outputs\n",
    "        # in-place, so we provide a fresh copy for each call\n",
    "        descriptors = torch.tensor(descriptors_arr, dtype=torch.float32)\n",
    "        targets = torch.tensor(targets_arr, dtype=torch.float32)\n",
    "        test_dataloader = fastpropDataLoader(fastpropDataset(descriptors[test_indexes], targets[test_indexes]), batch_size=1024)\n",
    "        test_predictions: np.ndarray = trainer.predict(real_model, test_dataloader)[0].numpy().ravel()\n",
    "        real_predictions.extend(test_predictions)\n",
    "        tensorboard_logger = TensorBoardLogger(\n",
    "            outdir,\n",
    "            name=\"tensorboard_logs\",\n",
    "            default_hp_metric=False,\n",
    "        )\n",
    "        trainer = Trainer(\n",
    "            max_epochs=30,\n",
    "            enable_progress_bar=False,\n",
    "            enable_model_summary=False,\n",
    "            logger=tensorboard_logger,\n",
    "            log_every_n_steps=1,\n",
    "            enable_checkpointing=False,\n",
    "            check_val_every_n_epoch=1,\n",
    "        )\n",
    "        trainer.fit(baseline_model, train_dataloader)\n",
    "        descriptors = torch.tensor(descriptors_arr, dtype=torch.float32)\n",
    "        targets = torch.tensor(targets_arr, dtype=torch.float32)\n",
    "        test_dataloader = fastpropDataLoader(fastpropDataset(descriptors[test_indexes], targets[test_indexes]), batch_size=1024)\n",
    "        test_predictions: np.ndarray = trainer.predict(baseline_model, test_dataloader)[0].numpy().ravel()\n",
    "        baseline_predictions.extend(test_predictions)\n",
    "        fold_truth.extend(targets[test_indexes].detach().clone().numpy().ravel())\n",
    "    return (\n",
    "        pearson_corrcoef(torch.tensor(real_predictions), torch.tensor(fold_truth)),\n",
    "        pearson_corrcoef(torch.tensor(baseline_predictions), torch.tensor(fold_truth)),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replicates\n",
    "Finally, we can train with replicates using the built in `train_and_test` function in `fastprop` - replicates are the reccomended way of running `fastprop`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastprop.model import train_and_test\n",
    "from astartes.molecules import train_val_test_split_molecules\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def replicate_fastprop(\n",
    "    smiles_arr: np.ndarray,\n",
    "    descriptors_arr: np.ndarray,\n",
    "    targets_arr: np.ndarray,\n",
    "    outdir: str,\n",
    "):\n",
    "    baseline_results, fastprop_results = [], []\n",
    "    for i in range(5):\n",
    "        # get a fresh copy of the input data for re-scaling\n",
    "        descriptors = torch.tensor(descriptors_arr, dtype=torch.float32)\n",
    "        targets = torch.tensor(targets_arr, dtype=torch.float32)\n",
    "\n",
    "        # split the data using kmeans clustering on the molecular fingerprint\n",
    "        *_, train_indexes, val_indexes, test_indexes = train_val_test_split_molecules(\n",
    "            smiles_arr,\n",
    "            train_size=0.8,\n",
    "            val_size=0.1,\n",
    "            test_size=0.1,\n",
    "            sampler=\"kmeans\",\n",
    "            random_state=42 + i,\n",
    "            return_indices=True,\n",
    "        )\n",
    "\n",
    "        baseline_model, real_model, train_dataloader, val_dataloader, test_dataloader = create_loaders_and_models(\n",
    "            descriptors, targets, train_indexes, val_indexes, test_indexes\n",
    "        )\n",
    "        test_results, validation_results = train_and_test(outdir, baseline_model, train_dataloader, val_dataloader, test_dataloader, quiet=True)\n",
    "        baseline_results.append(test_results[0])\n",
    "        test_results, validation_results = train_and_test(outdir, real_model, train_dataloader, val_dataloader, test_dataloader, quiet=True)\n",
    "        fastprop_results.append(test_results[0])\n",
    "    return (\n",
    "        pd.DataFrame.from_records(fastprop_results).describe().loc[\"mean\", \"test_r_score\"],\n",
    "        pd.DataFrame.from_records(baseline_results).describe().loc[\"mean\", \"test_r_score\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit a Model on each Task\n",
    "Now we can run `fastprop` on each of the tasks in this dataset!\n",
    "\n",
    "We will also add a `%%capture` cell magic to hide as much of the output from training as we can, since it's not helpful and it messes up notebook rendering.\n",
    "Remove that line to see all the details!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "from pathlib import Path\n",
    "\n",
    "fastprop_extrapolation = []\n",
    "fastprop_interpolation = []\n",
    "linear_extrapolation = []\n",
    "linear_interpolation = []\n",
    "for task_number in range(targets.shape[1]):\n",
    "    # select only the rows which have values\n",
    "    task_mask = ~np.isnan(targets[:, task_number])\n",
    "    # run the extrapolation\n",
    "    fastprop_result, baseline_result = replicate_fastprop(\n",
    "        smiles_arr=smiles[task_mask],\n",
    "        descriptors_arr=descriptors[task_mask, :],\n",
    "        targets_arr=targets[task_mask, task_number, None],  # keep it 2d\n",
    "        outdir=Path(f\"adme_output_task_{task_number}_extrapolation\"),\n",
    "    )\n",
    "    fastprop_extrapolation.append(fastprop_result)\n",
    "    linear_extrapolation.append(baseline_result)\n",
    "    # and the interpolation\n",
    "    fastprop_result, baseline_result = cross_validate_fastprop(\n",
    "        smiles_arr=smiles[task_mask],\n",
    "        descriptors_arr=descriptors[task_mask, :],\n",
    "        targets_arr=targets[task_mask, task_number, None],  # keep it 2d\n",
    "        outdir=Path(f\"adme_output_task_{task_number}_interpolation\"),\n",
    "    )\n",
    "    fastprop_interpolation.append(fastprop_result)\n",
    "    linear_interpolation.append(baseline_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a look at the results, organizing them into a nice table including the reference results from the source paper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "table = tabulate(\n",
    "    headers=[\"Model\"] + list(target_names.keys()),\n",
    "    tabular_data=[\n",
    "        [\"RF\", 0.62, 0.73, 0.57, 0.65, 0.75, 0.69],\n",
    "        [\"MPNN + Descriptors\", 0.68, 0.78, 0.59, 0.74, 0.77, 0.70],\n",
    "        [\"Linear\"] + linear_interpolation,\n",
    "        [\"fastprop\"] + fastprop_interpolation,\n",
    "        [\"Linear (KMeans)\"] + linear_extrapolation,\n",
    "        [\"fastprop (KMeans)\"] + fastprop_extrapolation,\n",
    "    ],\n",
    "    floatfmt=\".2f\",\n",
    ")\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`fastprop` is right in line with the methods presented in the reference study, matching Chemprop (MPNN + Descriptors) performance on HLM and Solubility, beating Random Forest (RF) on RLM, narrowly trailing both methods on MDR1-MDCK ER and rPPB, and falling significantly behind in hPPB.\n",
    "When moving to extrapolation, `fastprop`'s performance drops only a small amount on all tasks (_except_ hPPB) which is encouraging - this demonstrates that `fastprop` is capable of predicting in chemical space it has not seen during training!\n",
    "The reason hPPB improve under extrapolation is unknown.\n",
    "It could be because extrapolation turns out be easier for this _specific_ dataset, though this could also just be a product of the small dataset size (i.e. this is not a significant result).\n",
    "\n",
    "The linear model does quite poorly on some of the tasks under interpolation, though not extrapolation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make this easier to visualize, let's make a bar plot of the tasks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "try:\n",
    "    # this package makes nice plots but is a _pain_ to get working\n",
    "    # make the import optional\n",
    "    import scienceplots\n",
    "\n",
    "    plt.style.use(\"science\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "data = {\n",
    "    \"Linear\": linear_interpolation,\n",
    "    \"fastprop\": fastprop_interpolation,\n",
    "    \"RF\": [0.62, 0.73, 0.57, 0.65, 0.75, 0.69],\n",
    "    \"MPNN\": [0.68, 0.78, 0.59, 0.74, 0.77, 0.70],\n",
    "}\n",
    "\n",
    "# chatgpt plot\n",
    "values = np.array(list(data.values()))\n",
    "x = np.arange(len(target_names))  # the label locations\n",
    "width = 0.15  # the width of the bars\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "for i, model in enumerate(data.keys()):\n",
    "    ax.bar(x + i * width, values[i], width, label=model)\n",
    "ax.set_xlabel(\"Task\")\n",
    "ax.set_ylabel(\"Pearson's r\")\n",
    "ax.set_ylim(-0.1, 0.82)\n",
    "ax.grid(which='both', alpha=0.2)\n",
    "ax.set_axisbelow(True)\n",
    "ax.axhline(y=0, color='black', linewidth=0.8)\n",
    "ax.set_xticks(x + width * (len(data.keys()) - 1) / 2)\n",
    "ax.set_xticklabels(target_names.keys())\n",
    "plt.legend(loc=\"lower center\", ncol=len(data))\n",
    "plt.title(\"Computational ADME Per-Task Performance of Various Models\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fprop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
